import os
import json
import re
import uuid
from typing import List, Dict, Any
from openai import OpenAI
from chunks_minji import hybrid_search

from langchain_core.documents import Document

# åˆå§‹åŒ–DeepSeekå®¢æˆ·ç«¯
client = OpenAI(
    api_key=os.get("DEEPSEEK_API_KEY"),
    base_url="https://api.deepseek.com"
)

# åŠ è½½æç¤ºè¯é…ç½®
with open('common/prompts.json', 'r', encoding='utf-8') as f:
    PROMPT_CONFIG = json.load(f)


class ConversationManager:
    """å¯¹è¯ç®¡ç†å™¨ï¼Œç»´æŠ¤å¤šè½®å¯¹è¯å†å²"""

    def __init__(self, max_history_turns: int = 10):
        self.history = []
        self.max_history_turns = max_history_turns

    def add_message(self, role: str, content: str):
        """æ·»åŠ æ¶ˆæ¯åˆ°å¯¹è¯å†å²"""
        self.history.append({"role": role, "content": content})

        # ä¿æŒå†å²é•¿åº¦ä¸è¶…è¿‡æœ€å¤§å€¼
        if len(self.history) > self.max_history_turns * 2:
            self.history = self.history[-self.max_history_turns * 2:]

    def get_history(self) -> List[Dict[str, str]]:
        """è·å–å¯¹è¯å†å²"""
        return self.history.copy()

    def clear_history(self):
        """æ¸…ç©ºå¯¹è¯å†å²"""
        self.history = []


class QueryAnalyzer:
    """é—®é¢˜åˆ†æå™¨ï¼Œåˆ†è§£ç”¨æˆ·é—®é¢˜å¹¶ç”Ÿæˆå…³é”®è¯"""

    def __init__(self):
        self.system_prompt = PROMPT_CONFIG["query_analyzer"]["system_prompt"]

    def analyze_query(self, query: str, conversation_history: List[Dict] = None) -> Dict[str, Any]:
        """åˆ†æç”¨æˆ·é—®é¢˜å¹¶ç”Ÿæˆæœç´¢å…³é”®è¯"""
        try:
            # æ„å»ºå¯¹è¯å†å²ä¸Šä¸‹æ–‡
            messages = [{"role": "system", "content": self.system_prompt}]

            # å¦‚æœæœ‰å¯¹è¯å†å²ï¼Œæ·»åŠ æœ€è¿‘å‡ è½®ä½œä¸ºä¸Šä¸‹æ–‡
            if conversation_history:
                recent_history = conversation_history[-6:]
                messages.extend(recent_history)

            # æ·»åŠ å½“å‰é—®é¢˜
            messages.append({"role": "user", "content": f"è¯·åˆ†æä»¥ä¸‹é—®é¢˜ï¼š{query}"})

            response = client.chat.completions.create(
                model="deepseek-chat",
                messages=messages,
                max_tokens=800,
                stream=False,
                temperature=0.1
            )

            result_text = response.choices[0].message.content

            # å°è¯•è§£æJSON
            try:
                json_match = re.search(r'\{.*\}', result_text, re.DOTALL)
                if json_match:
                    result_json = json.loads(json_match.group())
                else:
                    result_json = json.loads(result_text)

                # éªŒè¯å¿…éœ€å­—æ®µ
                if "main_intent" not in result_json or "sub_queries" not in result_json:
                    raise ValueError("ç¼ºå°‘å¿…éœ€å­—æ®µ")

                return result_json

            except (json.JSONDecodeError, ValueError) as e:
                print(f"JSONè§£æå¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ: {e}")
                return {
                    "main_intent": query,
                    "sub_queries": self._fallback_keyword_extraction(query),
                    "search_strategy": "ç›´æ¥æœç´¢ç›¸å…³é—®é¢˜",
                    "raw_response": result_text
                }

        except Exception as e:
            print(f"é—®é¢˜åˆ†æå¤±è´¥: {e}")
            return {
                "main_intent": query,
                "sub_queries": self._fallback_keyword_extraction(query),
                "search_strategy": "ç›´æ¥æœç´¢åŸé—®é¢˜",
                "error": str(e)
            }

    def _fallback_keyword_extraction(self, query: str) -> List[str]:
        """å¤‡ç”¨å…³é”®è¯æå–æ–¹æ³•"""
        words = re.findall(r'[\u4e00-\u9fff]+|[a-zA-Z]+', query)
        stop_words = {'çš„', 'äº†', 'åœ¨', 'æ˜¯', 'æˆ‘', 'æœ‰', 'å’Œ', 'å°±', 'ä¸', 'äºº', 'éƒ½', 'ä¸€', 'ä¸€ä¸ª', 'ä¸Š', 'ä¹Ÿ', 'å¾ˆ',
                      'åˆ°', 'è¯´', 'è¦', 'å»', 'ä½ ', 'ä¼š', 'ç€', 'æ²¡æœ‰', 'çœ‹', 'å¥½', 'è‡ªå·±', 'è¿™'}
        keywords = [word for word in words if word not in stop_words and len(word) > 1]

        if len(keywords) < 2:
            return [query]

        return keywords[:4]


class QASystem:
    """é—®ç­”ç³»ç»Ÿï¼Œæ•´åˆæ£€ç´¢å’Œç”ŸæˆåŠŸèƒ½"""

    def __init__(self, vector_store, bm25_instance, all_splits):
        self.vector_store = vector_store
        self.bm25_instance = bm25_instance
        self.all_splits = all_splits
        self.conversation = ConversationManager()
        self.query_analyzer = QueryAnalyzer()

    def hybrid_search_documents(self, query: str, k: int = 3, context_range: int = 2,
                                semantic_weight: float = 0.6, bm25_weight: float = 0.4) -> List[Dict]:
        """
        ä½¿ç”¨æ··åˆæ£€ç´¢è·å–ç›¸å…³æ–‡æ¡£
        ç›´æ¥è°ƒç”¨chunks2ä¸­çš„hybrid_searchå‡½æ•°
        """

        return hybrid_search(
            self.vector_store,
            self.bm25_instance,
            self.all_splits,
            query,
            k,
            context_range,
            semantic_weight,
            bm25_weight
        )

    def call_deepseek_api(self, messages: List[Dict[str, str]], max_tokens: int = 2000) -> str:
        """è°ƒç”¨DeepSeek APIè¿›è¡Œé—®ç­”"""
        try:
            response = client.chat.completions.create(
                model="deepseek-chat",
                messages=messages,
                max_tokens=max_tokens,
                stream=False,
                temperature=0.3
            )
            return response.choices[0].message.content
        except Exception as e:
            return f"è°ƒç”¨DeepSeek APIæ—¶å‡ºé”™: {str(e)}"

    def process_query(self, query: str, k: int = 3, context_range: int = 2) -> Dict[str, Any]:
        """å¤„ç†ç”¨æˆ·æŸ¥è¯¢çš„å®Œæ•´æµç¨‹"""
        print(f"\nğŸ” åˆ†æé—®é¢˜: {query}")

        # 1. åˆ†æé—®é¢˜å¹¶ç”Ÿæˆå…³é”®è¯
        # analysis_result = self.query_analyzer.analyze_query(
        #     query,
        #     self.conversation.get_history()
        # )
        #
        # print(f"ğŸ“ ä¸»è¦æ„å›¾: {analysis_result['main_intent']}")
        # print(f"ğŸ”‘ æœç´¢å…³é”®è¯: {analysis_result['sub_queries']}")
        # print(f"ğŸ¯ æœç´¢ç­–ç•¥: {analysis_result.get('search_strategy', 'N/A')}")

        # 2. ä½¿ç”¨æ··åˆæ£€ç´¢æœç´¢æ–‡æ¡£
        search_results = self.hybrid_search_documents(
            query,
            k,
            context_range
        )

        # if not search_results:
        #     result = {
        #         "query": query,
        #         "analysis": analysis_result,
        #         "error": "æœªæ‰¾åˆ°ç›¸å…³æ–‡æ¡£",
        #         "answer": "æŠ±æ­‰ï¼Œæˆ‘æ²¡æœ‰æ‰¾åˆ°ä¸æ‚¨é—®é¢˜ç›¸å…³çš„ä¿¡æ¯ã€‚è¯·å°è¯•æ¢ä¸€ç§æ–¹å¼æé—®ã€‚"
        #     }

        #     # æ·»åŠ åˆ°å¯¹è¯å†å²
        #     self.conversation.add_message("user", query)
        #     self.conversation.add_message("assistant", result["answer"])
        #     return result

        # 3. æ„å»ºä¸Šä¸‹æ–‡å†…å®¹ - å°†hybrid_searchè¿”å›çš„ç»“æœä¼ é€’ç»™AI
        context_parts = []
        for result in search_results:
            content = result["content"]
            source = result["source"]
            context_parts.append(f"ã€æ¥æº: {source}ã€‘\n{content}")

            # æ·»åŠ ä¸Šä¸‹æ–‡æ®µè½ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            for context_item in result.get("context", []):
                context_content = context_item["content"]
                context_source = context_item["source"]
                context_parts.append(f"ã€ç›¸å…³ä¸Šä¸‹æ–‡ - æ¥æº: {context_source}ã€‘\n{context_content}")

        full_context = "\n\n".join(context_parts)

        # 4. æ„å»ºæ¶ˆæ¯å¹¶è°ƒç”¨API
        system_prompt = PROMPT_CONFIG["answer_generator"]["system_prompt"]

        messages = [{"role": "system", "content": system_prompt}]

        # æ·»åŠ å¯¹è¯å†å²
        messages.extend(self.conversation.get_history())

        # æ·»åŠ ä¸Šä¸‹æ–‡å’Œå½“å‰é—®é¢˜ - è¿™é‡Œå°†æ£€ç´¢åˆ°çš„å†…å®¹ä¼ é€’ç»™AI
        user_message = f"åŸºäºä»¥ä¸‹æ£€ç´¢åˆ°çš„æ–‡æ¡£å†…å®¹å›ç­”é—®é¢˜ï¼š\n\n{full_context}\n\né—®é¢˜ï¼š{query}"
        print(user_message)
        messages.append({"role": "user", "content": user_message})

        # è°ƒç”¨APIç”Ÿæˆç­”æ¡ˆ
        ai_answer = self.call_deepseek_api(messages)

        # 6. æ›´æ–°å¯¹è¯å†å²
        self.conversation.add_message("user", query)
        self.conversation.add_message("assistant", ai_answer)

        return ai_answer







